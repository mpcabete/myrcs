#! /bin/python3

import openai
import sys
import tiktoken
encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")


usr_input = " ".join(sys.argv[2:])

model = "gpt-3.5-turbo"
target_language = sys.argv[1]

def num_tokens_from_messages(messages):
    """Returns the number of tokens used by a list of messages."""
    tokens_per_message = 4  # every message follows <|start|>{role/name}\n{content}<|end|>\n
    tokens_per_name = -1  # if there's a name, the role is omitted

    num_tokens = 0
    for message in messages:
        num_tokens += tokens_per_message
        for key, value in message.items():
            num_tokens += len(encoding.encode(value))
            if key == "name":
                num_tokens += tokens_per_name
    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>
    return num_tokens

def make_comment(target_language, plain_text):
    if target_language == "python":
        return f"# {plain_text}"
    elif target_language == "java":
        return f"// {plain_text}"
    elif target_language == "javascript":
        return f"// {plain_text}"
    elif target_language == "c":
        return f"/* {plain_text} */"
    elif target_language == "c++":
        return f"// {plain_text}"
    elif target_language == "lua":
        return f"-- {plain_text}"
    else:
        return f"Unsupported language: {target_language}"


# list models
# models = openai.Model.list()


messages = [
    {
        "role": "system",
        "content": f"You are a code generator for the {target_language} programming language"
    },
    {
        "role": "user",
        "content": f"""You will output ONLY valid {target_language} code.
 - generate code on a advanced level.
 - The code should not be wrapped in backticks.
 - Do not explain the code.
 - Use only comments to document the code.
 Here is what you should write: 
 {usr_input}"""
    },
]
tokens = num_tokens_from_messages(messages)



# Define a function to calculate the number of tokens in a given string using the GPT API





response = openai.ChatCompletion.create(
    model=model,
    messages=messages,
    temperature=0.7,
    max_tokens=500,
    stream=True,
)


for chunk in response:
    delta = chunk.choices[0].delta
    if "content" in delta:
        print (delta.content,end='',flush=True)



pricePerMilTokens = 0.002

# result = response.choices[0].message.content
# print(result)
#
# tokens += len(encoding.encode(result))
#
# print(response.usage.total_tokens)
# print(tokens)
#
# cost_string = "%.5f Centavos" % (
#     (response.usage.total_tokens / 10 * 5) * pricePerMilTokens
# )
# cost_commented = make_comment(target_language, cost_string)
#
# print(cost_commented)

